{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "---\n",
    "\n",
    "A machine learning system that learns to predict probability of binary distribution of variables.\n",
    "\n",
    "Used to classify different events based on the predicted probability of its occurence.\n",
    "\n",
    "Used to classify > 3 different events if multiple logistic regression models are trained in a sort of (1 vs All algorithm).\n",
    "\n",
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys, os, re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "# NEVER FORGET MATPLOTLIB INLINE!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class LogRegData:\n",
    "    def __init__(self):\n",
    "        path = \"/Users/codetesting/machinelearn/Code/logisticReg/ex2\"\n",
    "        # this is interpreted as absolute because it does have a leading '/'\n",
    "\n",
    "        ex2data1 = os.path.join(path, \"ex2data1.txt\")\n",
    "\n",
    "        # with open(ex2data1) as ex2data:\n",
    "        #     data = ex2data.read()\n",
    "        # with statement --> ex2data.closed = true\n",
    "        self.y = []\n",
    "        self.X = []\n",
    "        self.posX1 = []\n",
    "        self.posX2 = []\n",
    "        self.negX1 = []\n",
    "        self.negX2 = []\n",
    "        with open(ex2data1) as ex2data1:\n",
    "            for line in ex2data1:\n",
    "                values = re.split(\",\", line.strip()) # splits line on ,\n",
    "                values = map(float, values) # converts list of strings to float\n",
    "                self.X.append(values[:2]) # makes X an m x 2 list (adds a list to X)\n",
    "                self.y.append(values[2]) # makes Y an m x 1 list\n",
    "                if values[2] == 1:\n",
    "                    self.posX1.append(values[0])\n",
    "                    self.posX2.append(values[1])\n",
    "                else:\n",
    "                    self.negX1.append(values[0])\n",
    "                    self.negX2.append(values[1])\n",
    "                    \n",
    "    def plot(self):\n",
    "        plt.scatter(posX1,posX2,c='r',marker='x')\n",
    "        plt.scatter(negX1,negX2,c='b',marker='o')\n",
    "        plt.xlim(30,100)\n",
    "        plt.ylim(30,100)\n",
    "        plt.xlabel(\"Exam 1 Score\")\n",
    "        plt.ylabel(\"Exam 2 Score\")\n",
    "        plt.show()\n",
    "        return plt\n",
    "    \n",
    "    def getXandY(self):\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All data taken from Prof. Ng's Machine Learning class on Coursera.\n",
    "\n",
    "Thank you!\n",
    "\n",
    "## Algorithms [(LaTeX)](http://stackoverflow.com/questions/13208286/how-to-write-latex-in-ipython-notebook)\n",
    "\n",
    "The Hypothesis Function is defined as:\n",
    "$$ h_\\theta(x) = g(\\theta'*X) $$\n",
    "\n",
    "                                            where g(x) is the sigmoid function\n",
    "$$ g(x) = sigmoid(x) = \\frac{1}{1 + e^{-x}} $$\n",
    "\n",
    "The Cost Function is defined as:\n",
    "$$ J(\\theta) = \\frac{1}{m} \\sum_{i=1}^{m} \\big[-y^{(i)} log(h_\\theta(x^{(i)})) - (1-y^{(i)}) log(1- h_\\theta(x^{(i)}))\\big] $$\n",
    "\n",
    "                                            the derivative of J is defined:\n",
    "$$ \\frac{\\partial J(\\theta)}{\\partial \\theta_j} = \\frac{1}{m} \\sum_{i=1}^{m} \\big(h_\\theta(x^{(i)}) - y^{(i)}\\big) x_j^{(i)} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# names = [1,2,3,4,5,6,7,8,9,10]\n",
    "# print [x for x in names if x == 1]\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    Where x is an array or matrix, np.exp()\n",
    "    returns an equally sized array with its elements\n",
    "    set to e^(that element)\n",
    "    \"\"\"\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def J(theta, X, y):\n",
    "    \"\"\"\n",
    "    Returns the cost of the function h(x) and the \n",
    "    gradient of h(x) given the current theta parameters\n",
    "    \"\"\"\n",
    "    m = len(x)\n",
    "    grad = np.zeros(np.shape(theta))\n",
    "    \n",
    "    p1 = np.dot(-y, np.log(sigmoid(np.dot(X,theta))))\n",
    "    p2 = np.dot(np.transpose(1-y), np.log(1-sigmoid(np.dot(X,theta))))\n",
    "    cost = (p1-p2) / m\n",
    "    \n",
    "    grad = np.transpose(np.dot(np.transpose(sigmoid(np.dot(X,theta))-y),X))/m;\n",
    "    return cost, grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "554.517744448\n"
     ]
    }
   ],
   "source": [
    "data = LogRegData()\n",
    "X, y = data.getXandY()\n",
    "cost, grad = J(np.zeros([2,1]),X,y)\n",
    "print cost[0]\n",
    "# Seems to be working\n",
    "# Next step is to check with the Cost of the initial theta parameters given"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
